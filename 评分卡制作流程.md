# Credit-Risk-ScoreCards-Process 评分卡的制作流程

分享本人对评分卡制作流程的认识，希望可以为作为风控人员提供协助决策的工具。

- [一.决定业务目标、评分卡类型及组建开发人员](#一决定业务目标评分卡类型及组建开发团队)
- 二.数据处理
- 三.变量分析
- 四.模型开发
- 五.模型评估
- 六.生成评分卡
- 七.评分卡上线、测试、监控、调整

## 一.决定业务目标、评分卡类型及组建开发团队

针对不同业务、不同产品、不同场景，评分卡的变量选取、分数范围、分布，均有不同调整，所以在第一步应该确认业务目标、产品、场景，选定评分卡类型。

此处只针对信贷业务，以消费贷（产品）为例，可以分为3种场景：贷前、贷中、贷后，分别对应3种评分卡：A卡（申请评分卡），B卡（行为评分卡），C卡（催收评分卡）。

在开发评分卡前，应该要组建相应的开发人员，包括但不限于以下职位：

- 数据分析师

负责处理评分卡涉及到的数据，如数据采集、清洗、挖掘、加工等

- 风控经理

对整个业务有深入的了解，可以从业务层面解释评分卡，包括每个变量的意义、评分卡分数分布、评分卡好坏的定义，同时需要指导模型开发人员在开发过程中注意那些可能违背业务逻辑的变量

- 模型开发人员

配合数据分析师，将数据进行聚类、分箱，采用合适的算法（逻辑回归、决策树等），拟合模型并对模型进行评估，最终将之转化成标准化评分卡。

- 评分卡执行者

评分卡完成后，需要执行者布置到测试、生产环境上，同时需要对评分卡进行测试、监控、调整。

## 二.数据处理

在上述步骤决定后，就开始真正对评分卡进行开发。

数据处理，主要是获取数据和对数据进行简单分析。

- 数据获取

  一般数据获取的过程，主要由数据分析师完成。一个评分卡的质量上限很大程度取决于数据质量，数据质量越好，评分卡的质量越好，数据获取需要前期的积累，通常需要风控经理协助，根据业务经验，设计好需要收集的数据的相关字段。

- 探索性数据分析
  
  探索性数据分析（Exploratory Data Analysis）简称EDA，内容包括：描述性统计、评估每个变量值的分布并检验正态假设、异常值的识别和处理、缺失值的计算和处理、等等
  
  - 描述性统计
  
    描述性统计是对变量的统计学属性进行分析，如：平均值，中位数，总数，标准差等等。
    
  - 变量值分布
  
    连续型变量：直方图。一般而言，需要满足正态分布，才具有意义。
    
    离散型变量：饼图或条形图。一般而言，离散型变量的某一个值如果占总体比例极低（如5%以下），该值应该和其他取值合并；但这并非绝对的，某些值可能具有极强的预测能力。
    
  - 异常值识别和处理
    - 识别方法：
    
      连续型变量：某值远离正态分布的均值，比如某值在（均值±3*标准差）的范围以外
      
      离散型变量：某值的出现次数占总体次数的1%以下
      
    - 处理方法：
    
      值替换
      
    另外，如果异常值超过10%，表明获取数据的流程可能存在设计上的漏洞（比如申请时要求填写联系人关系，原应设计成给定的可选项，但设计成填写项，这就导致各种异常值的存在，就像“大姨妈”），需要重新设计获取的流程。
    
  - 缺失值处理
    - 直接剔除
    - 根据样本之间的相似性填补（统计替换）
    - 根据变量之间的相关性填补（拟合）

## 三.变量分析

  如何在众多的变量中，找到合适的变量，是这一阶段需要解决的问题。

  在变量选择的过程中，需要遵循4个原则：
  
  - 可解释性：变量从业务层面是可解释的
  - 低相关性：各个变量间的相关性是相对较低的
  - 易获取性：变量是容易获取
  - 强预测性：变量对目标变量的具有相对较强的预测能力

  下面将介绍如何在选择变量时围绕上述4个原则做分析
  
  - 可解释性
    
    假设目前有2个变量需要选择，1个是**身份证号**，1个是**多头数**，在有限的样本中，不考虑相关性，模型开发者发现**身份证号***对目标变量（比如是否逾期）的预测*比**多头数***对目标变量的预测能力*相对更强，在这种情况下，理应选择**身份证号**作为变量，但是从正常逻辑上讲，**身份证号**是一个随机的数值，与目标变量无法产生联系，从业务层面完全无法解释，因此**身份证号**作为变量是不合理的，在这种情况下，须选择预测能力相对较弱的**多头数**作为变量。
    
    **多头数**业务解释：申请人在多个平台申请贷款，申请次数越多，其资金紧张的可能性或欺诈可能性就越高，这些对申请人而言都是负面信息。
  
    因此在选择变量时，需要从业务层面对其进行解释，虽然可解释性无法用具体的量化指标评估，但开发者应自己先对其进行解释，如果无法解释，可以寻求业务经验丰富的风控经理协助。
    
  - 低相关性
    
    相关性可以从两个方面分析：单变量相关性，多变量相关性（多重共线性），这2个都有具体的指标可以用来评估。高相关性和多重共线性会使模型的预测功能失效。因此为保证模型是有效的，单变量相关性及多变量相关性均应保持在一个低水平。
    
    - 单变量相关性评估指标：皮尔逊（Pearson）相关系数
    - 多变量相关性评估指标：VIF共线性
    
    例如：针对某个工薪贷的产品，如果设计的变量有工资年总收入、工资月均收入、个人所得税、社保缴费金额，那么很明显这几个变量是高度相关。
    
    因此在选择变量时，需要考虑变量的相关性，如果其相关系数超过预先设定的临界值，或者存在多重共线性，那么开发者对该变量就需要特别小心，结合其他原则与综合风控经理的建议，决定是否保留变量。
    
  - 易获取性
  
    易获取性没有具体的指标，但是有具体的定义，满足下面几个条件才能叫具有易获取性：
    - 合规：变量要满足合规性，不要搞一些超纲的变量。
    - 低成本：某些变量具有很高的预测能力，但是其获取成本极高，比如针对生意贷，企业的纳税数据，如果要获取，需要对接第三方数据或者建立爬虫团队，这就要评估付出的成本是否可以带来相应的收益了，更建议的方式是用其他变量替代。
    - 无须鉴真：变量应该是无须判断真伪的，在获取时就应该有极大几率判定该值是真实的。如自填的学历就不是一个很好的变量，自填是无法判断是否真实的，申请人可能会为了提高通过率，故意将低学历填写成高学历，这样的变量是失真的。当然，如果学历是非自填，而是由学信网等官方网站验证后获取，那还是可取的。
    - 异常率低：变量的异常率不宜过高，高异常率将使变量失效，从而影响整个模型的效果。
    - 缺失率低：变量的缺失率不宜过高，高缺失率将使变量失效，从而影响整个模型的效果。
  
  - 强预测性
    
    预测能力是衡量变量好坏的重要指标，一般预测能力的权重比其余3个原则高，预测能力有具体的评估指标。
    
    - 信息价值（Information Value，简称IV值）
      
      IV是评分卡模型中的一个常见指标，其作用主要是衡量变量的预测能力的大小。一般而言，IV值越高，变量的预测能力越强。鉴于IV值的重要性，此处分几个问题展开详述。
    
      - IV值如何计算？
      
        假设变量有n个分箱
        
        每个分箱对应的好客户分别为g1,g2,...,gn
        
        每个分箱对应的坏客户分别为b1,b2,...,bn
        
        好客户总数G = g1+g2+...+gn
        
        坏客户总数B = b1+b2+...+bn
        
        那么IV = LN[(g1/G)÷(b1/B)] * [(g1/G)-(b1/B)] + LN[(g2/G)÷(b2/B)] * [(g2/G)-(b2/B)] + ... + LN[(gn/G)÷(bn/B)] * [(gn/G)-(bn/B)]
        
        上面的LN[(g1/G)÷(b1/B)] * [(g1/G)-(b1/B)]其实就是WOE，这个后面会讲到，此处先跳过。
        
        纯文字描述可能比较难看，请结合表格理解
        
        ![image](https://github.com/Firlovice/Credit-Risk-ScoreCards-Process/blob/master/IV%E5%80%BC%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F.jpg)
        
        实例 (变量：年龄，分箱4个：18-25,26-45,46-55,56-60，好客户总数：9500，坏客户总数：500，IV值：**0.10055153**）
        
        ![image](https://github.com/Firlovice/Credit-Risk-ScoreCards-Process/blob/master/IV%E5%80%BC%E8%AE%A1%E7%AE%97%E5%AE%9E%E4%BE%8B.jpg)
        
        IV值计算表格[下载](https://github.com/Firlovice/Credit-Risk-ScoreCards-Process/blob/master/IV%E5%80%BC%E8%AE%A1%E7%AE%97.xlsx)
        
      - IV值多少算好？
        
        针对不同的场景，对IV值的好坏范围并没有一个评判标准，下面是由一般经验（[出处](http://ucanalytics.com/blogs/information-value-and-weight-of-evidencebanking-case/)）得出的范围，评分卡可以借鉴。
        
        ![image](https://github.com/Firlovice/Credit-Risk-ScoreCards-Process/blob/master/IV%E5%80%BC%E8%8C%83%E5%9B%B4.jpg)
        
        根据个人经验，如果IV值低于0.1基本可以将该变量列入待排除的名单中，但是如果该变量的具有一定的业务解释能力，那么是否引用仍待商榷。
        
      - IV值越高越好吗？
        
        参考上图，当IV>0.5，可以得出预测能力强的难以置信的结论，在这种情况下，这是否表明IV值越高越好？**并非如此！**以下两种情况均会导致IV值偏高：
        
          - 变量的分箱数过多
          - 部分分箱中的好客户或坏客户数极少（非0）     
        
        这两种情况均不是一个好的现象。
        
        第一种情况，分箱没有分好。分箱越多，该变量的约没有分箱的必要性，当分箱遍历了所有的可能值，比如年龄分箱1:18，分箱2:19，分箱3:20，...，分箱42:59，分,43:60，虽然能另IV值很高，但是已经失去了分箱的意义了。
        
        第二种情况，当部分分箱出现的好客户或坏客户极少情况下，此时对应的IV值很高，建议直接将其设置成规则，而非作为评分卡变量。
        
        如下图，IV值约为6.53，年龄18-55的好坏分化明显，此时应直接设置规则“年龄>55周岁，拒绝”
        ![image](https://github.com/Firlovice/Credit-Risk-ScoreCards-Process/blob/master/IV%E5%80%BC%E6%83%85%E5%86%B52.jpg)
        
      - IV值会出现异常值吗？
          
        会！当某个分箱的好客户或坏客户的数量为0时，对应的IV值分别是-∞或+∞，所以模型开发者在分箱时一定需要注意该情况的出现。
          
      - IV值与其他原则如何权衡？
        
        简单来说，在其他原则相同的情况下，优先选IV值高的变量。
        
        根据个人喜好及经验，在4个原则中，预测能力的权重应该在60%左右。
        
## 四.模型开发

开发流程：选定变量（非最终变量、需要迭代）、变量分箱（连续：卡方、best-ks；离散：最优IV、卡方）、WOE化、训练模型：逻辑回归、






## 五.模型评估

  在模型开发完成后，我们需要对模型进行评估，如果模型的效果未达到理想值，这时的模型是不可用的，这时需要重新开发模型。
  
  一个模型是否优秀，必须从三个方面进行评估：区分度、准确性、稳定性

  这三个方面都有具体的指标用以评估：
  
  - 区分度：KS、GINI系数
  - 准确性：ROC、AUC
  - 稳定性：PSI
  
  为了可以更清晰地讲解上述指标，必须先引入一个概念作为前置知识点：混淆矩阵

  - 混淆矩阵
  
  混淆矩阵其实也是评判模型结果的指标，属于模型评估的一部分，适用于分类型的数据模型。网上的介绍一搜一堆，这里只讲解用到的内容。
  
  假设现在有一个样本数据，里面有10000个客户，并且知道这些客户的实际好坏情况，将这些客户带入模型中，那么就会预测每一个客户是好客户还是坏客户，整理可得到下表（第二、三列的1表示坏客户，0表示好客户）
  
  ![image](https://github.com/Firlovice/Credit-Risk-ScoreCards-Process/blob/master/%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5%E6%A0%B7%E6%9C%AC%E6%95%B0%E6%8D%AE.jpg)

  有了上表的数据，统计可得到下表
  
  ![image](https://github.com/Firlovice/Credit-Risk-ScoreCards-Process/blob/master/%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5.jpg)
  
  上表的各个数据表示：
  
名称|对应数据
-|-
客户总量|10000
实际好客户|9500
实际坏客户|500
预测好客户|9000
预测坏客户|1000
实际好客户且预测为好客户|8700
实际好客户但预测为坏客户|800
实际坏客户但预测为好客户|300
实际坏客户且预测为坏客户|200

  将上面的表格一般化，就是混淆矩阵。

 ![image](https://github.com/Firlovice/Credit-Risk-ScoreCards-Process/blob/master/%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B51.jpg)

名称|定义|业务层面解释
-|-|-
TP(True Positive)|实际为0，预测为0|好客户预测为好客户，即正确预测好客户，此类客户放款可带来收益
FN(False Negative)|实际为0，预测为1|好客户预测为坏客户，即错误预测为坏客户，此类客户拒绝将损失好客户带来的利息，又可以叫“误杀”
FP(False Positive)|实际为1，预测为0|坏客户预测为好客户，即错误预测为好客户，此类客户由于错误预测，放款后带来严重损失，又可以叫“漏杀”
TN(True Negative)|实际为0，预测为0|坏客户预测为坏客户，即正确预测坏客户，此类客户拒绝可避免损失

理解了上面后，对上面4个值进行加工就得到下面的内容

 ![image](https://github.com/Firlovice/Credit-Risk-ScoreCards-Process/blob/master/%E7%9C%9F%E5%81%87%E6%AD%A3%E8%B4%9F%E7%8E%87.jpg)



## 六.生成评分卡

转化为标准评分





## 七.评分卡上线、测试、监控、调整






