# Credit-Risk-ScoreCards-Process 评分卡的制作流程

简述整个评分卡的制作流程，为风控人员提供协助决策的工具。

- 一.决定业务目标、评分卡类型及组建开发人员
- 二.数据处理
- 三.变量分析
- 四.模型开发
- 五.模型评估
- 六.生成评分卡
- 七.评分卡上线、测试、监控、调整

## 一.决定业务目标、评分卡类型及组建开发团队

针对不同业务、不同产品、不同场景，评分卡的变量选取、分数范围、分布，均有不同调整，所以在第一步应该确认业务目标、产品、场景，选定评分卡类型。

此处只针对信贷业务，以消费贷（产品）为例，可以分为3种场景：贷前、贷中、贷后，分别对应3种评分卡：A卡（申请评分卡），B卡（行为评分卡），C卡（催收评分卡）。

在开发评分卡前，应该要组建相应的开发人员，包括但不限于以下职位：

- 数据分析师

负责处理评分卡涉及到的数据，如数据采集、清洗、挖掘、加工等

- 风控经理

对整个业务有深入的了解，可以从业务层面解释评分卡，包括每个变量的意义、评分卡分数分布、评分卡好坏的定义，同时需要指导模型开发人员在开发过程中注意那些可能违背业务逻辑的变量

- 模型开发人员

配合数据分析师，将数据进行聚类、分箱，采用合适的算法（逻辑回归、决策树等），拟合模型并对模型进行评估，最终将之转化成标准化评分卡。

- 评分卡执行者

评分卡完成后，需要执行者布置到测试、生产环境上，同时需要对评分卡进行测试、监控、调整。

## 二.数据处理

在上述步骤决定后，就开始真正对评分卡进行开发。

数据处理，主要是获取数据和对数据进行简单分析。

- 数据获取
  一般数据获取的过程，主要由数据分析师完成。一个评分卡的质量上限很大程度取决于数据质量，数据质量越好，评分卡的质量越好，数据获取需要前期的积累，通常需要风控经理协助，根据业务经验，设计好需要收集的数据的相关字段。

- 探索性数据分析
  
  探索性数据分析（Exploratory Data Analysis）简称EDA，内容包括：描述性统计、评估每个变量值的分布并检验正态假设、异常值的识别和处理、缺失值的计算和处理、等等
  
  - 描述性统计
  
    描述性统计是对变量的统计学属性进行分析，如：平均值，中位数，总数，标准差等等。
    
  - 变量值分布
  
    连续型变量：直方图。一般而言，需要满足正态分布，才具有意义。
    
    离散型变量：饼图或条形图。一般而言，离散型变量的某一个值如果占总体比例极低（如5%以下），该值应该和其他取值合并；但这并非绝对的，某些值可能具有极强的预测能力。
    
  - 异常值识别和处理
    - 识别方法：
    
      连续型变量：某值远离正态分布的均值，比如某值在（均值±3*标准差）的范围以外
      
      离散型变量：某值的出现次数占总体次数的1%以下
      
    - 处理方法：
    
      值替换
      
    另外，如果异常值超过10%，表明获取数据的流程可能存在设计上的漏洞（比如申请时要求填写联系人关系，原应设计成给定的可选项，但设计成填写项，这就导致各种异常值的存在，就像“大姨妈”），需要重新设计获取的流程。
    
  - 缺失值处理
    - 直接剔除
    - 根据样本之间的相似性填补（统计替换）
    - 根据变量之间的相关性填补（拟合）

## 三.变量分析

  如何在众多的变量中，找到合适的变量，是这一阶段需要解决的问题。

  在变量选择的过程中，需要遵循4个原则：
  
  - 可解释性：变量从业务层面是可解释的
  - 低相关性：各个变量间的相关性是相对较低的
  - 易获取性：变量是容易获取
  - 强预测性：变量对目标变量的具有相对较强的预测能力

  下面将介绍如何在选择变量时围绕上述4个原则做分析
  
  - 可解释性
    
    假设目前有2个变量需要选择，1个是**身份证号**，1个是**多头数**，在有限的样本中，不考虑相关性，模型开发者发现**身份证号***对目标变量（比如是否逾期）的预测*比**多头数***对目标变量的预测能力*相对更强，在这种情况下，理应选择**身份证号**作为变量，但是从正常逻辑上讲，**身份证号**是一个随机的数值，与目标变量无法产生联系，从业务层面完全无法解释，因此**身份证号**作为变量是不合理的，在这种情况下，须选择预测能力相对较弱的**多头数**作为变量。
    
    **多头数**业务解释：申请人在多个平台申请贷款，申请次数越多，其资金紧张的可能性或欺诈可能性就越高，这些对申请人而言都是负面信息。
  
    因此在选择变量时，需要从业务层面对其进行解释，虽然可解释性无法用具体的量化指标评估，但开发者应自己先对其进行解释，如果无法解释，可以寻求业务经验丰富的风控经理协助。
    
  - 低相关性
    
    相关性可以从两个方面分析：单变量相关性，多变量相关性（多重共线性），这2个都有具体的指标可以用来评估。高相关性和多重共线性会使模型的预测功能失效。因此为保证模型是有效的，单变量相关性及多变量相关性均应保持在一个低水平。
    
    - 单变量相关性评估指标：皮尔逊（Pearson）相关系数
    - 多变量相关性评估指标：VIF共线性
    
    例如：针对某个工薪贷的产品，如果设计的变量有工资年总收入、工资月均收入、个人所得税、社保缴费金额，那么很明显这几个变量是高度相关。
    
    因此在选择变量时，需要考虑变量的相关性，如果其相关系数超过预先设定的临界值，或者存在多重共线性，那么开发者对该变量就需要特别小心，结合其他原则与综合风控经理的建议，决定是否保留变量。
    
  - 易获取性
  
    易获取性没有具体的指标，但是有具体的定义，满足下面几个条件才能叫具有易获取性：
    - 合规：变量要满足合规性，不要搞一些超纲的变量。
    - 低成本：某些变量具有很高的预测能力，但是其获取成本极高，比如针对生意贷，企业的纳税数据，如果要获取，需要对接第三方数据或者建立爬虫团队，这就要评估付出的成本是否可以带来相应的收益了，更建议的方式是用其他变量替代。
    - 无须鉴真：变量应该是无须判断真伪的，在获取时就应该有极大几率判定该值是真实的。如自填的学历就不是一个很好的变量，自填是无法判断是否真实的，申请人可能会为了提高通过率，故意将低学历填写成高学历，这样的变量是失真的。当然，如果学历是非自填，而是由学信网等官方网站验证后获取，那还是可取的。
    - 异常率低：变量的异常率不宜过高，高异常率将使变量失效，从而影响整个模型的效果。
    - 缺失率低：变量的缺失率不宜过高，高缺失率将使变量失效，从而影响整个模型的效果。
  
  - 强预测性
    
    预测能力是衡量变量好坏的重要指标，一般预测能力的权重比其余3个原则高，预测能力有具体的评估指标。
    
    - 信息价值（Information Value，简称IV值）
      
      IV是评分卡模型中的一个常见指标，其作用主要是衡量变量的预测能力的大小。一般而言，IV值越高，变量的预测能力越强。鉴于IV值的重要性，此处分几个问题展开详述。
    
      - IV值如何计算？
      
        为方便讲解，先建立一个简单场景，现有样本数据m条    
        假设变量有n个分箱，每个分箱对应的好客户分别为\\(g(1)、g(2)、g(3)、g(n)\\)
      
      - IV值多少算好？
      
        http://ucanalytics.com/blogs/information-value-and-weight-of-evidencebanking-case/
        
      - IV值越高越好吗？
      
      - IV值会出现异常值吗？如果出现异常值如何处理？
      
      - IV值与其他原则如何权衡？
    
