# Credit-Risk-ScoreCards-Process 评分卡的制作流程

分享本人对评分卡制作流程的认识，希望可以为作为风控人员提供协助决策的工具。

- [一.决定业务目标、评分卡类型及组建开发人员](#一决定业务目标评分卡类型及组建开发团队)
- [二.数据处理](#二数据处理)
- [三.变量分析](#三变量分析)
- [四.模型开发](#四模型开发)
- [五.生成评分卡](#五生成评分卡)
- [六.模型评估](#六模型评估)
- [七.评分卡上线、测试、监控、调整](#七评分卡上线测试监控调整)

## 一.决定业务目标、评分卡类型及组建开发团队

针对不同业务、不同产品、不同场景，评分卡的变量选取、分数范围、分布，均有不同调整，所以在第一步应该确认业务目标、产品、场景，选定评分卡类型。

此处只针对信贷业务，以消费贷（产品）为例，可以分为3种场景：贷前、贷中、贷后，分别对应3种评分卡：A卡（申请评分卡），B卡（行为评分卡），C卡（催收评分卡）。

在开发评分卡前，应该要组建相应的开发人员，包括但不限于以下职位：

- 数据分析师

负责处理评分卡涉及到的数据，如数据采集、清洗、挖掘、加工等

- 风控经理

对整个业务有深入的了解，可以从业务层面解释评分卡，包括每个变量的意义、评分卡分数分布、评分卡好坏的定义，同时需要指导模型开发人员在开发过程中注意那些可能违背业务逻辑的变量

- 模型开发人员

配合数据分析师，将数据进行聚类、分箱，采用合适的算法（逻辑回归、决策树等），拟合模型并对模型进行评估，最终将之转化成标准化评分卡。

- 评分卡执行者

评分卡完成后，需要执行者布置到测试、生产环境上，同时需要对评分卡进行测试、监控、调整。

## 二.数据处理

在上述步骤决定后，就开始真正对评分卡进行开发。

数据处理，主要是获取数据和对数据进行简单分析。

- 数据获取

  一般数据获取的过程，主要由数据分析师完成。一个评分卡的质量上限很大程度取决于数据质量，数据质量越好，评分卡的质量越好，数据获取需要前期的积累，通常需要风控经理协助，根据业务经验，设计好需要收集的数据的相关字段。

- 探索性数据分析
  
  探索性数据分析（Exploratory Data Analysis）简称EDA，内容包括：描述性统计、评估每个变量值的分布并检验正态假设、异常值的识别和处理、缺失值的计算和处理、等等
  
  - 描述性统计
  
    描述性统计是对变量的统计学属性进行分析，如：平均值，中位数，总数，标准差等等。
    
  - 变量值分布
  
    连续型变量：直方图。一般而言，需要满足正态分布，才具有意义。
    
    离散型变量：饼图或条形图。一般而言，离散型变量的某一个值如果占总体比例极低（如5%以下），该值应该和其他取值合并；但这并非绝对的，某些值可能具有极强的预测能力。
    
  - 异常值识别和处理
    - 识别方法：
    
      连续型变量：某值远离正态分布的均值，比如某值在（均值±3*标准差）的范围以外
      
      离散型变量：某值的出现次数占总体次数的1%以下
      
    - 处理方法：
    
      值替换
      
    另外，如果异常值超过10%，表明获取数据的流程可能存在设计上的漏洞（比如申请时要求填写联系人关系，原应设计成给定的可选项，但设计成填写项，这就导致各种异常值的存在，就像“大姨妈”），需要重新设计获取的流程。
    
  - 缺失值处理
    - 直接剔除
    - 根据样本之间的相似性填补（统计替换）
    - 根据变量之间的相关性填补（拟合）

## 三.变量分析

  如何在众多的变量中，找到合适的变量，是这一阶段需要解决的问题。

  在变量选择的过程中，需要遵循4个原则：
  
  - 可解释性：变量从业务层面是可解释的
  - 低相关性：各个变量间的相关性是相对较低的
  - 易获取性：变量是容易获取
  - 强预测性：变量对目标变量的具有相对较强的预测能力

  下面将介绍如何在选择变量时围绕上述4个原则做分析
  
  - 可解释性
    
    假设目前有2个变量需要选择，1个是**身份证号**，1个是**多头数**，在有限的样本中，不考虑相关性，模型开发者发现**身份证号***对目标变量（比如是否逾期）的预测*比**多头数***对目标变量的预测能力*相对更强，在这种情况下，理应选择**身份证号**作为变量，但是从正常逻辑上讲，**身份证号**是一个随机的数值，与目标变量无法产生联系，从业务层面完全无法解释，因此**身份证号**作为变量是不合理的，在这种情况下，须选择预测能力相对较弱的**多头数**作为变量。
    
    **多头数**业务解释：申请人在多个平台申请贷款，申请次数越多，其资金紧张的可能性或欺诈可能性就越高，这些对申请人而言都是负面信息。
  
    因此在选择变量时，需要从业务层面对其进行解释，虽然可解释性无法用具体的量化指标评估，但开发者应自己先对其进行解释，如果无法解释，可以寻求业务经验丰富的风控经理协助。
    
  - 低相关性
    
    相关性可以从两个方面分析：单变量相关性，多变量相关性（多重共线性），这2个都有具体的指标可以用来评估。高相关性和多重共线性会使模型的预测功能失效。因此为保证模型是有效的，单变量相关性及多变量相关性均应保持在一个低水平。
    
    - 单变量相关性评估指标：皮尔逊（Pearson）相关系数
    - 多变量相关性评估指标：VIF共线性
    
    例如：针对某个工薪贷的产品，如果设计的变量有工资年总收入、工资月均收入、个人所得税、社保缴费金额，那么很明显这几个变量是高度相关。
    
    因此在选择变量时，需要考虑变量的相关性，如果其相关系数超过预先设定的临界值，或者存在多重共线性，那么开发者对该变量就需要特别小心，结合其他原则与综合风控经理的建议，决定是否保留变量。
    
  - 易获取性
  
    易获取性没有具体的指标，但是有具体的定义，满足下面几个条件才能叫具有易获取性：
    - 合规：变量要满足合规性，不要搞一些超纲的变量。
    - 低成本：某些变量具有很高的预测能力，但是其获取成本极高，比如针对生意贷，企业的纳税数据，如果要获取，需要对接第三方数据或者建立爬虫团队，这就要评估付出的成本是否可以带来相应的收益了，更建议的方式是用其他变量替代。
    - 无须鉴真：变量应该是无须判断真伪的，在获取时就应该有极大几率判定该值是真实的。如自填的学历就不是一个很好的变量，自填是无法判断是否真实的，申请人可能会为了提高通过率，故意将低学历填写成高学历，这样的变量是失真的。当然，如果学历是非自填，而是由学信网等官方网站验证后获取，那还是可取的。
    - 异常率低：变量的异常率不宜过高，高异常率将使变量失效，从而影响整个模型的效果。
    - 缺失率低：变量的缺失率不宜过高，高缺失率将使变量失效，从而影响整个模型的效果。
  
  - 强预测性
    
    预测能力是衡量变量好坏的重要指标，一般预测能力的权重比其余3个原则高，预测能力有具体的评估指标。
    
    - 信息价值（Information Value，简称IV值）
      
      IV是评分卡模型中的一个常见指标，其作用主要是衡量变量的预测能力的大小。一般而言，IV值越高，变量的预测能力越强。鉴于IV值的重要性，此处分几个问题展开详述。
    
      - IV值如何计算？
      
        假设变量有n个分箱
        
        每个分箱对应的好客户分别为g1,g2,...,gn
        
        每个分箱对应的坏客户分别为b1,b2,...,bn
        
        好客户总数G = g1+g2+...+gn
        
        坏客户总数B = b1+b2+...+bn
        
        那么IV = LN[(g1/G)÷(b1/B)] * [(g1/G)-(b1/B)] + LN[(g2/G)÷(b2/B)] * [(g2/G)-(b2/B)] + ... + LN[(gn/G)÷(bn/B)] * [(gn/G)-(bn/B)]
        
        上面的LN[(g1/G)÷(b1/B)] * [(g1/G)-(b1/B)]其实就是WOE，这个后面会讲到，此处先跳过。
        
        纯文字描述可能比较难看，请结合表格理解
        
        ![image](https://github.com/Firlovice/Credit-Risk-ScoreCards-Process/blob/master/IV%E5%80%BC%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F.jpg)
        
        实例 (变量：年龄，分箱4个：18-25,26-45,46-55,56-60，好客户总数：9500，坏客户总数：500，IV值：**0.10055153**）
        
        ![image](https://github.com/Firlovice/Credit-Risk-ScoreCards-Process/blob/master/IV%E5%80%BC%E8%AE%A1%E7%AE%97%E5%AE%9E%E4%BE%8B.jpg)
        
        IV值计算表格[下载](https://github.com/Firlovice/Credit-Risk-ScoreCards-Process/blob/master/IV%E5%80%BC%E8%AE%A1%E7%AE%97.xlsx)
        
      - IV值多少算好？
        
        针对不同的场景，对IV值的好坏范围并没有一个评判标准，下面是由一般经验（[出处](http://ucanalytics.com/blogs/information-value-and-weight-of-evidencebanking-case/)）得出的范围，评分卡可以借鉴。
        
        ![image](https://github.com/Firlovice/Credit-Risk-ScoreCards-Process/blob/master/IV%E5%80%BC%E8%8C%83%E5%9B%B4.jpg)
        
        根据个人经验，如果IV值低于0.1基本可以将该变量列入待排除的名单中，但是如果该变量的具有一定的业务解释能力，那么是否引用仍待商榷。
        
      - IV值越高越好吗？
        
      参考上图，当IV>0.5，可以得出预测能力强的难以置信的结论，在这种情况下，这是否表明IV值越高越好？**并非如此！**以下两种情况均会导致IV值偏高：
        
          - 变量的分箱数过多
          - 部分分箱中的好客户或坏客户数极少（非0）     
        
        这两种情况均不是一个好的现象。
        
        第一种情况，分箱没有分好。分箱越多，该变量的约没有分箱的必要性，当分箱遍历了所有的可能值，比如年龄分箱1:18，分箱2:19，分箱3:20，...，分箱42:59，分,43:60，虽然能另IV值很高，但是已经失去了分箱的意义了。
        
        第二种情况，当部分分箱出现的好客户或坏客户极少情况下，此时对应的IV值很高，建议直接将其设置成规则，而非作为评分卡变量。
        
        如下图，IV值约为6.53，年龄18-55的好坏分化明显，此时应直接设置规则“年龄>55周岁，拒绝”
        ![image](https://github.com/Firlovice/Credit-Risk-ScoreCards-Process/blob/master/IV%E5%80%BC%E6%83%85%E5%86%B52.jpg)
        
      - IV值会出现异常值吗？
          
        会！当某个分箱的好客户或坏客户的数量为0时，对应的IV值分别是-∞或+∞，所以模型开发者在分箱时一定需要注意该情况的出现。
          
      - IV值与其他原则如何权衡？
        
        简单来说，在其他原则相同的情况下，优先选IV值高的变量。
        
        根据个人喜好及经验，在4个原则中，预测能力的权重应该在60%左右。
        
## 四.模型开发

开发流程：选定变量（非最终变量、需要迭代）——> 变量分箱（连续：卡方、best-ks；离散：最优IV、卡方）——> 数据WOE化 ——> 模型训练：逻辑回归 ——> 显著性检验

### 选定变量
  经过变量分析，这一步需要选定入模的变量，但是这些变量是否能作为最终的变量现在仍无法确认，还需要对变量的分箱情况、分箱对应的IV，以及拟合后显著性进行观察。
  
### 变量分箱

  - 为什么分箱？
  
    参考一下别人的文章[《为什么要进行数据分箱？（转）》](http://www.cnblogs.com/gczr/p/9316606.html)
  
  - 如何分箱？
  
    分箱方法比较多，如何选择最合适的分箱方法也是一个问题。常见的分为有监督、无监督两类。
    
    - 有监督分箱：卡方（ChiMerge）、best-ks、最优IV
    
    - 无监督分箱：等频、等距、聚类
    
    针对不同的变量类型，应该用不同的分箱方法，从个人经验来看，连续型变量常用卡方分箱，离散型变量常用最优IV分箱。
  
  - 实现工具
  
    建议python，理由：简单、灵活。

  下面详细介绍有监督分箱方法的原理、步骤及案例！

#### 卡方分箱（ChiMerge）

  原理转自[《ChiMerge 算法》](https://blog.csdn.net/qunxingvip/article/details/50449376)，[步骤转自《Python评分卡建模—卡方分箱》](https://www.sohu.com/a/224569101_793685)

  - 原理
  
  ChiMerge是监督的、自底向上的(即基于合并的)数据离散化方法。它依赖于卡方检验：具有最小卡方值的相邻区间合并在一起，直到满足确定的停止准则。基本思想：对于精确的离散化，相对类频率在一个区间内应当完全一致。因此，如果两个相邻的区间具有非常类似的类分布，则这两个区间可以合并；否则，它们应当保持分开。而低卡方值表明它们具有相似的类分布。 

  - 步骤
  
  主要包括两个阶段：初始化阶段和自底向上的合并阶段。
  
  1.初始化阶段：
  
  首先按照属性值的大小进行排序（对于非连续特征，需要先做数值转换，比如转为坏人率，然后排序），然后每个属性值单独作为一组。
  
  2.合并阶段：
  
  （1）对每一对相邻的组，计算卡方值。
  
  （2）根据计算的卡方值，对其中最小的一对邻组合并为一组。
  
  （3）不断重复（1），（2）直到计算出的卡方值都不低于事先设定的阈值，或者分组数达到一定的条件（如最小分组数5，最大分组数8）。
  
  - 案例
  
    暂无
  
#### best-ks分箱

  - 原理
  
  自上向下拆分数据，将排好序的数据，通过KS值计算出其差异程度最高对应的值，以该值为临界点把数据拆分成左右两部，循环此过程，直到将数据拆分至满足终止条件。由于每次都通过差异程度最高的临界值拆分区间，最后得到的分箱可让组别的分布的差异最大化。
  
  - 步骤
  
  
  
  - 案例
  
    暂无

#### 最优IV分箱

  - 原理
  
  
  
  - 步骤
  
  
  
  - 案例

    暂无






## 五.生成评分卡

转化为标准评分




## 六.模型评估

  在模型开发完成后，我们需要对模型进行评估，如果模型的效果未达到理想值，这时的模型是不可用的，这时需要重新开发模型。
  
  一个模型是否优秀，必须从三个方面进行评估：区分度、准确性、稳定性

  这三个方面都有具体的指标用以评估：
  
  - 区分度：[KS](#KS值)、[GINI系数](#GINI系数)
  - 准确性：[ROC曲线](#ROC曲线)、[AUC](#AUC)
  - 稳定性：[PSI](#PSI)
  
  为了可以更清晰地讲解上述指标，必须先引入一个概念作为前置知识点：混淆矩阵

  - 混淆矩阵
  
  混淆矩阵其实也是评判模型结果的指标，属于模型评估的一部分，适用于分类型的数据模型。网上的介绍一搜一堆，这里只讲解用到的内容。
  
  > 假设现在有一个样本数据，里面有10000个客户，并且知道这些客户的实际好坏情况，将这些客户带入模型中，那么就会得到每一个客户的预测值（假设已经转化成标准化评分卡），将预测值≥600分的客户视为好客户，预测值＜600分的客户视为坏客户，整理可得到下表（第二、三列的1表示坏客户，0表示好客户）
  
  ![image](https://github.com/Firlovice/Credit-Risk-ScoreCards-Process/blob/master/%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5%E6%A0%B7%E6%9C%AC%E6%95%B0%E6%8D%AE.jpg)

  有了上表的数据，统计可得到下表
  
  ![image](https://github.com/Firlovice/Credit-Risk-ScoreCards-Process/blob/master/%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5.jpg)
  
  上表的各个数据表示：
  
名称|对应数据
-|-
客户总量|10000
实际好客户|9500
实际坏客户|500
预测好客户|9000
预测坏客户|1000
实际好客户且预测为好客户|8700
实际好客户但预测为坏客户|800
实际坏客户但预测为好客户|300
实际坏客户且预测为坏客户|200

  将上面的表格一般化，就是混淆矩阵。

 ![image](https://github.com/Firlovice/Credit-Risk-ScoreCards-Process/blob/master/%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B51.jpg)

名称|定义|业务层面解释
-|-|-
TP(True Positive)|实际为0，预测为0|好客户预测为好客户，即正确预测好客户，此类客户放款可带来收益
FN(False Negative)|实际为0，预测为1|好客户预测为坏客户，即错误预测为坏客户，此类客户拒绝将损失好客户带来的利息，又可以叫“误杀”
FP(False Positive)|实际为1，预测为0|坏客户预测为好客户，即错误预测为好客户，此类客户由于错误预测，放款后带来严重损失，又可以叫“漏杀”
TN(True Negative)|实际为0，预测为0|坏客户预测为坏客户，即正确预测坏客户，此类客户拒绝可避免损失

理解了上面后，对上面4个值进行加工就得到下面的内容

 ![image](https://github.com/Firlovice/Credit-Risk-ScoreCards-Process/blob/master/%E7%9C%9F%E5%81%87%E6%AD%A3%E8%B4%9F%E7%8E%87.jpg)

混淆矩阵表格[下载](https://github.com/Firlovice/Credit-Risk-ScoreCards-Process/blob/master/%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5.xlsx)

充分了解上面内容后，就可以开始介绍模型评估的指标了！

### KS值
  - 用途：评估模型区分能力
  - 公式：Max(TPR-FPR)
  - 取值范围：[0,1]，KS值越大，区分能力越强，模型越好，KS>0.2时表示模型有一点区分能力
  - 常见疑问点：
    - 1.公式是不是有问题？混淆矩阵里的值不都是定值吗？TPR是定值，FPR也是定值，定值减定值还是定值啊？Max一个定值没有意义啊！难道数学是体育老师教的？
    - 2.为什么网上有些KS不是这样计算？比如[《神秘的KS值和GINI系数》](https://blog.csdn.net/u013421629/article/details/78217498)
    - 3.算出来的KS值是负的？不按套路出牌？
  - 解答：
    - 1.公式没有问题！只是理解的角度不对，为了能够更加简单地找对这个角度，下面还是以案例说明。
    
  > 假设现在有一个样本数据，里面有n个客户，并且知道这些客户的实际好坏情况，将这些客户带入模型中，那么就会得到每一个客户的预测值（假设已经转化成标准化评分卡），将预测值≥临界值x分的客户视为好客户，预测值＜临界值x分的客户视为坏客户。（是不是似曾相识？！）
  
  在这个案例中，n是样本总数，在采样时就决定了，无法改变。而在给定了一个临界值x时（如600），可以得到对应的TPR_1与FPR_1；同样的，在给定另一个临界值y后，可以得到其对应的TPR_2与FPR_2。由此得出，**TPR和FPR是根据临界值x变动而变动的，也即TPR、FPR是关于临界值x的函数**。
  
  现在将 n 个客户的预测值去重后进行排序，得到一个含有 m 个预测值（m ≤ n）的列表[s1, s2, ..., sm]，将这 m 个值分别作为临界值计算其对应的 TPR 和 FPR ，分别得出列表[TPR_1, TPR_2, ..., TPR_m] 和 [FPR_1, FPR_2, ..., FPR_m]，如下图。
  
  ![magie](https://github.com/Firlovice/Credit-Risk-ScoreCards-Process/blob/master/KS%E6%A1%88%E4%BE%8B.jpg)
  
  最后，计算每一对TPR-FPR的值，选出最大的那一个值，它就是KS了，也即Max(TPR-FPR)
  
  - 2.先说结论：两种计算方式实际上是一样的，计算出的值也是一样的。
  
  按照那篇文章，KS的计算不需要涉及TPR或者FPR，也没有临界值的事，以案例说明。
  
  > 假设现在有一个样本数据，里面有n个客户，并且知道这些客户的实际好坏情况，将这些客户带入模型中，那么就会得到每一个客户的预测值（假设已经转化成标准化评分卡）。将所有预测值去重后进行排序（由小到大）。

  案例没有TPR/FPR/临界值，此时统计每一个预测值对应的好客户和坏客户数量，加工可得下图所有数据，然后将第一列作为横坐标，最右两列作为纵坐标，画出来就是那篇文章的那个图。

  ![magie](https://github.com/Firlovice/Credit-Risk-ScoreCards-Process/blob/master/KS%E6%A1%88%E4%BE%8B2.jpg)

  求每一对**好客户累计占比**与**坏客户累计占比**的差的绝对值的最大值就是KS值。是不是有点拗口？直接点：Max(Abs(好客户累计占比-坏客户累计占比))

  - 3.Max(|TPR-FPR|)，即先求绝对值，再求最大值。这个和好坏客户的定义有关，比如将600分以上视作好客户，相反地，可以将600分以上视作坏客户。
  
  KS表[下载](https://github.com/Firlovice/Credit-Risk-ScoreCards-Process/blob/master/KS%E8%A1%A8.xlsx)
  
### GINI系数
  - 用途：评估模型区分能力
  - 公式：2AUC-1 或 2(AUC-0.5)。GINI系数等于ROC曲线与对角线之间面积的两倍。
  - 范围：[-1,1]，GINI等于0代表完全随机，1代表完美区分能力，-1代表完美反向区分能力，一般认为GINI>0.6比较好。

### ROC曲线
  - 用途：评估模型准确性
  - 公式：没有公式，这是一个曲线，以FPR作为横坐标，TPR作为纵坐标（不是定值，不懂的回去看KS值第一个常见疑问点），做散点图，将每一点连接起来形成一条曲线。
  - 图例
  
  ![magie](https://github.com/Firlovice/Credit-Risk-ScoreCards-Process/blob/master/ROC%E6%9B%B2%E7%BA%BF%E5%9B%BE.jpg)

### AUC
  - 用途：评估模型准确性
  
  这个[wiki百科](https://zh.wikipedia.org/wiki/ROC%E6%9B%B2%E7%BA%BF#%E6%9B%B2%E7%B7%9A%E4%B8%8B%E9%9D%A2%E7%A9%8D%EF%BC%88AUC%EF%BC%89)讲解的非常清晰，建议直接看wiki的，下面引用部分:
  
  - 公式：求ROC曲线下的面积，一般用梯形法，简单地将每个相邻的点以直线连接，计算连线下方的总面积。
  - 范围：[0,1]，从AUC判断分类器（预测模型）优劣的标准：
    - AUC = 1，是完美分类器，采用这个预测模型时，存在至少一个阈值能得出完美预测。绝大多数预测的场合，不存在完美分类器。
    - 0.5 < AUC < 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。
    - AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。
    - AUC < 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。

### PSI
  - 用途：评估模型稳定性
  - 公式：Sum((Ac-Ex）* Ln(Ac/Ex))，Ac是实际占比，Ex是预期占比。仔细看，和IV的计算是类似的。
  - 计算步骤：
    
    1.将输出变量（如信用评分）由小到大排序，然后等距（或等频）分组（如10组）。
    
    2.将实际样本、预测样本分别按上述分组统计数量。
    
    3.计算实际样本、预测样本在每个分组的比率。
    
    4.根据公式计算其PSI.
    
  - 范围：

PSI|稳定性
-|-
PSI<0.1|模型稳定性高
0.1<PSI<0.25|模型稳定性中等
PSI>0.25|模型稳定性较差

  - 不同维度的示例：
  
    - 样本：不同的样本测试稳定性，比如训练集和测试集。
    - 时间：不同时间测试稳定性，建模的样本与模型运行后采集的新样本，可以检测模型在后续的稳定性，由此判定是否需要更新模型。
    
  下以案例说明：
    
> 假设模型运作了已有半年，现要评估其稳定性，根据建模时的分数分布（假设建模采用了10000个客户），以及实际运行后随机抽样的客户（假设抽取5000个），整理成下表。 PSI约为0.0183。

![magie](https://github.com/Firlovice/Credit-Risk-ScoreCards-Process/blob/master/PSI%E5%9B%BE.jpg)
  





## 七.评分卡上线、测试、监控、调整






